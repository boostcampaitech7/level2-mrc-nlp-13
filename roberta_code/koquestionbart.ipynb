{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# KoBART를 활용한 질문 생성 관련 Multitasking\nHosted on huggingface! [rycont/KoQuestionBART](https://huggingface.co/rycont/KoQuestionBART)\n\n사용한 데이터셋: KorQuad 1.0 Trainset\n\n한국어 문단에서 의미있는 질문을 생성하기 위해 다음과 같은 태스크를 멀티태스크로 학습한 모델입니다.\n- 문단에서 답변이 될 수 있는 키워드 추출\n- 키워드를 답변으로 할 수 있는 문장 생성\n\n## 사용 방법\n### 키워드 추출\n**입력**\n> [키워드 갯수]\\<unused1>[문단]\n    \n**출력**\n> [키워드1]\\<unused2>[키워드1]\\<unused2>[키워드n...\n\n### 질문 생성\n**입력**\n> [답변]\\<unused0>[문단]\n\n**출력**\n> [질문 문장]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:03:28.952708Z","iopub.execute_input":"2022-04-08T08:03:28.953362Z","iopub.status.idle":"2022-04-08T08:03:28.958146Z","shell.execute_reply.started":"2022-04-08T08:03:28.953316Z","shell.execute_reply":"2022-04-08T08:03:28.957147Z"}}},{"cell_type":"code","source":"!wget https://korquad.github.io/dataset/KorQuAD_v1.0_train.json","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:08:54.346656Z","iopub.execute_input":"2022-04-09T10:08:54.347007Z","iopub.status.idle":"2022-04-09T10:08:57.02987Z","shell.execute_reply.started":"2022-04-09T10:08:54.346917Z","shell.execute_reply":"2022-04-09T10:08:57.028955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install pytorch_lightning===1.4.9 transformers","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:08:57.032348Z","iopub.execute_input":"2022-04-09T10:08:57.032619Z","iopub.status.idle":"2022-04-09T10:09:08.734449Z","shell.execute_reply.started":"2022-04-09T10:08:57.032583Z","shell.execute_reply":"2022-04-09T10:09:08.733571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nfrom pytorch_lightning import loggers as pl_loggers\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import (BartForConditionalGeneration,\n                          PreTrainedTokenizerFast)\nfrom transformers.optimization import AdamW, get_cosine_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom itertools import chain\nfrom torch.utils.tensorboard import SummaryWriter\nimport json\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:08.736184Z","iopub.execute_input":"2022-04-09T10:09:08.736462Z","iopub.status.idle":"2022-04-09T10:09:17.060187Z","shell.execute_reply.started":"2022-04-09T10:09:08.736427Z","shell.execute_reply":"2022-04-09T10:09:17.05833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.__version__","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:17.063938Z","iopub.execute_input":"2022-04-09T10:09:17.064395Z","iopub.status.idle":"2022-04-09T10:09:17.074563Z","shell.execute_reply.started":"2022-04-09T10:09:17.064359Z","shell.execute_reply":"2022-04-09T10:09:17.073474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetFromDataframe(Dataset):\n    def __init__(self, df, tokenizer, max_seq_len=512) -> None:\n        self.data = df\n        self.max_seq_len = max_seq_len\n        self.tokenizer = tokenizer\n        self.bos_token = '<s>'\n        self.eos_token = '</s>'\n\n    def __len__(self):\n        return len(self.data)\n\n    # input id masker.\n    # if input text is shorter than max_length, fill with padding token <pad>\n    # if it is longer, cut and and with end token </s>\n    \n    def make_input_id_mask(self, tokens, index):\n        input_id = self.tokenizer.convert_tokens_to_ids(tokens)\n        attention_mask = [1] * len(input_id)\n        if len(input_id) < self.max_seq_len:\n            while len(input_id) < self.max_seq_len:\n                input_id += [self.tokenizer.pad_token_id]\n                attention_mask += [0]\n        else:\n            print(f'exceed max_seq_len for given article : {index}')\n            input_id = input_id[:self.max_seq_len - 1] + [ self.tokenizer.eos_token_id ]\n            attention_mask = attention_mask[:self.max_seq_len]\n        return input_id, attention_mask\n\n    def __getitem__(self, index):\n        record = self.data.iloc[index]\n        \n        if 'input_id' in record.keys():\n            q, a = record['input_id'], record['target_id']\n\n            q_tokens = [ self.bos_token ] + q + [ self.eos_token ]\n            a_tokens = [ self.bos_token ] + a + [ self.eos_token ]\n\n        else:\n            q, a = record['input_text'], record['target_text']\n\n            q_tokens = [ self.bos_token ] + self.tokenizer.tokenize(q) + [ self.eos_token ]\n            a_tokens = [ self.bos_token ] + self.tokenizer.tokenize(a) + [ self.eos_token ]\n        \n        encoder_input_id, encoder_attention_mask = self.make_input_id_mask(q_tokens, index)\n        decoder_input_id, decoder_attention_mask = self.make_input_id_mask(a_tokens, index)\n        \n        labels = self.tokenizer.convert_tokens_to_ids(\n            a_tokens[1:(self.max_seq_len + 1)]\n        )\n\n        # WTF is this??\n        if len(labels) < self.max_seq_len:\n            while len(labels) < self.max_seq_len:\n                # for cross entropy loss masking\n                labels += [-100]\n\n        return {\n            'input_ids': np.array(encoder_input_id, dtype=np.int_),\n            'attention_mask': np.array(encoder_attention_mask, dtype=np.float_),\n            'decoder_input_ids': np.array(decoder_input_id, dtype=np.int_),\n            'decoder_attention_mask': np.array(decoder_attention_mask, dtype=np.float_),\n            'labels': np.array(labels, dtype=np.int_)\n        }","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:17.07634Z","iopub.execute_input":"2022-04-09T10:09:17.076864Z","iopub.status.idle":"2022-04-09T10:09:17.093632Z","shell.execute_reply.started":"2022-04-09T10:09:17.076823Z","shell.execute_reply":"2022-04-09T10:09:17.092697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class OneSourceDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        filepath,\n        custom_dataset,\n        tokenizer,\n        max_length = 36,\n        batch_size = 8\n    ):\n        super().__init__()\n        \n        if type(filepath) is str:\n            self.filepath = filepath\n            self.data = False\n        else:\n            self.filepath = False\n            self.data = filepath\n        \n        self.custom_dataset = custom_dataset\n        self.tokenizer = tokenizer\n        self.max_seq_len = max_length\n        self.batch_size = batch_size\n        \n        self.num_workers = 2\n        self.train_size = 0.9\n\n    def setup(self, stage=\"\"):\n        df = pd.read_csv(self.filepath) if self.filepath else self.data\n        trainset, testset = train_test_split(df, train_size=self.train_size, shuffle=True)\n        \n        self.trainset = self.custom_dataset(trainset, self.tokenizer, self.max_seq_len)\n        self.testset = self.custom_dataset(testset, self.tokenizer, self.max_seq_len)\n\n    def train_dataloader(self):\n        train = DataLoader(\n            self.trainset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            shuffle=True\n        )\n        return train\n\n    def val_dataloader(self):\n        val = DataLoader(\n            self.testset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            shuffle=True\n        )\n        return val\n\n    def test_dataloader(self):\n        test = DataLoader(\n            self.testset,\n            batch_size=self.batch_size,\n            num_workers=self.num_workers,\n            shuffle=False\n        )\n        return test","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:17.094883Z","iopub.execute_input":"2022-04-09T10:09:17.095279Z","iopub.status.idle":"2022-04-09T10:09:17.109379Z","shell.execute_reply.started":"2022-04-09T10:09:17.095242Z","shell.execute_reply":"2022-04-09T10:09:17.108547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Base(pl.LightningModule):\n    def __init__(self, hparams, **kwargs) -> None:\n        super(Base, self).__init__()\n        self.hparams.update(hparams)\n\n    def configure_optimizers(self):\n        # Prepare optimizer\n        param_optimizer = list(self.model.named_parameters())\n        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in param_optimizer if not any(\n                nd in n for nd in no_decay)], 'weight_decay': 0.01},\n            {'params': [p for n, p in param_optimizer if any(\n                nd in n for nd in no_decay)], 'weight_decay': 0.0}\n        ]\n        optimizer = AdamW(optimizer_grouped_parameters,\n                          lr=self.hparams.lr, correct_bias=False)\n        # warm up lr\n        num_workers = (self.hparams.gpus if self.hparams.gpus is not None else 1) * (self.hparams.num_nodes if self.hparams.num_nodes is not None else 1)\n        data_len = len(self.train_dataloader().dataset)\n        print(f'number of workers {num_workers}, data length {data_len}')\n        num_train_steps = int(data_len / (self.hparams.batch_size * num_workers) * self.hparams.max_epochs)\n        print(f'num_train_steps : {num_train_steps}')\n        num_warmup_steps = int(num_train_steps * self.hparams.warmup_ratio)\n        print(f'num_warmup_steps : {num_warmup_steps}')\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n        lr_scheduler = {'scheduler': scheduler, \n                        'monitor': 'loss', 'interval': 'step',\n                        'frequency': 1}\n        return [optimizer], [lr_scheduler]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:17.110895Z","iopub.execute_input":"2022-04-09T10:09:17.111228Z","iopub.status.idle":"2022-04-09T10:09:17.123719Z","shell.execute_reply.started":"2022-04-09T10:09:17.111117Z","shell.execute_reply":"2022-04-09T10:09:17.122906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class KoBARTConditionalGeneration(Base):\n    def __init__(self, hparams, **kwargs):\n        super(KoBARTConditionalGeneration, self).__init__(hparams, **kwargs)\n        \n        self.model = kwargs['model']\n        self.tokenizer = kwargs['tokenizer']\n        self.model.train()\n        \n        self.bos_token = tokenizer.bos_token\n        self.eos_token = tokenizer.eos_token\n\n    def forward(self, inputs):\n        return self.model(\n            input_ids=inputs['input_ids'],\n            attention_mask=inputs['attention_mask'],\n            decoder_input_ids=inputs['decoder_input_ids'],\n            decoder_attention_mask=inputs['decoder_attention_mask'],\n            labels=inputs['labels'], return_dict=True\n        )\n\n    def training_step(self, batch, batch_idx):\n        outs = self(batch)\n        loss = outs.loss\n        self.log('train_loss', loss, prog_bar=True, on_step=True, on_epoch=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        outs = self(batch)\n        loss = outs['loss']\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n\n\n    def chat(self, text):\n        input_ids =  [self.tokenizer.bos_token_id] + self.tokenizer.encode(text) + [self.tokenizer.eos_token_id]\n        res_ids = self.model.generate(\n            torch.tensor([input_ids]),\n            max_length=self.hparams.max_seq_len,\n            num_beams=6,\n            eos_token_id=self.tokenizer.eos_token_id,\n            bad_words_ids=[[self.tokenizer.unk_token_id]]\n        )\n        a = self.tokenizer.batch_decode(res_ids.tolist())[0]\n        return a.replace('<s>', '').replace('</s>', '')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:17.125262Z","iopub.execute_input":"2022-04-09T10:09:17.125763Z","iopub.status.idle":"2022-04-09T10:09:17.140029Z","shell.execute_reply.started":"2022-04-09T10:09:17.125722Z","shell.execute_reply":"2022-04-09T10:09:17.139306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = PreTrainedTokenizerFast.from_pretrained(\n    \"gogamza/kobart-base-v2\",\n    bos_token=\"<s>\",\n    eos_token=\"</s>\",\n    unk_token='<unk>',\n    pad_token='<pad>',\n    mask_token='<mask>'\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:17.14129Z","iopub.execute_input":"2022-04-09T10:09:17.141538Z","iopub.status.idle":"2022-04-09T10:09:22.427569Z","shell.execute_reply.started":"2022-04-09T10:09:17.141502Z","shell.execute_reply":"2022-04-09T10:09:22.426812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"./KorQuAD_v1.0_train.json\", \"r\") as f:\n    korquad = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:22.431051Z","iopub.execute_input":"2022-04-09T10:09:22.431324Z","iopub.status.idle":"2022-04-09T10:09:23.547228Z","shell.execute_reply.started":"2022-04-09T10:09:22.431288Z","shell.execute_reply":"2022-04-09T10:09:23.546387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getTextPairFromKorquad(korquad):\n    COLUMN_NAMES = ['input_text', 'target_text']\n    \n    paragraphs = list(chain.from_iterable([[paragraph for paragraph in article['paragraphs']] for article in korquad['data']]))\n\n    questionPair = pd.DataFrame(list(chain.from_iterable([[\n        [ questionItem['answers'][0]['text'] + \"<unused0>\" + paragraph['context'], questionItem['question'] ]\n        for questionItem in paragraph['qas'] if len(questionItem['answers'])\n    ] for paragraph in paragraphs])), columns=COLUMN_NAMES)\n    \n    keywordPair = pd.DataFrame(\n        [ [paragraph['context'], list(set([ questionItem['answers'][0]['text'] for questionItem in paragraph['qas'] if len(questionItem['answers'])])) ] for paragraph in paragraphs ]\n        , columns=COLUMN_NAMES\n    )\n    \n    keywordCounts = keywordPair['target_text'].apply(len)\n    keywordPair = keywordPair[keywordCounts > 3]\n    keywordCounts = keywordCounts.apply(str)\n    \n    keywordPair['input_text'] = keywordCounts + \"<unused1>\" + keywordPair['input_text']\n    keywordPair['target_text'] = keywordPair['target_text'].apply(lambda keywords: \"<unused2>\".join(keywords))\n    \n    keywordPair['input_text'] = \"키워드 추출\" + \": \" + keywordPair['input_text']\n    questionPair['input_text'] = \"질문 생성\" + \": \" + questionPair['input_text']\n    \n    return questionPair, keywordPair","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.548654Z","iopub.execute_input":"2022-04-09T10:09:23.548906Z","iopub.status.idle":"2022-04-09T10:09:23.55995Z","shell.execute_reply.started":"2022-04-09T10:09:23.548871Z","shell.execute_reply":"2022-04-09T10:09:23.559189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"korquadQ, korquadK = getTextPairFromKorquad(korquad)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.56147Z","iopub.execute_input":"2022-04-09T10:09:23.561905Z","iopub.status.idle":"2022-04-09T10:09:23.846866Z","shell.execute_reply.started":"2022-04-09T10:09:23.561863Z","shell.execute_reply":"2022-04-09T10:09:23.846184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"korquadQ = korquadQ.sample(frac=1)\nkorquadK = korquadK.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.848214Z","iopub.execute_input":"2022-04-09T10:09:23.84848Z","iopub.status.idle":"2022-04-09T10:09:23.865869Z","shell.execute_reply.started":"2022-04-09T10:09:23.848446Z","shell.execute_reply":"2022-04-09T10:09:23.865176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(korquadQ), len(korquadK)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.867308Z","iopub.execute_input":"2022-04-09T10:09:23.867578Z","iopub.status.idle":"2022-04-09T10:09:23.874656Z","shell.execute_reply.started":"2022-04-09T10:09:23.867544Z","shell.execute_reply":"2022-04-09T10:09:23.873874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"korquadQ = korquadQ.iloc[:len(korquadK)]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.876234Z","iopub.execute_input":"2022-04-09T10:09:23.876883Z","iopub.status.idle":"2022-04-09T10:09:23.881929Z","shell.execute_reply.started":"2022-04-09T10:09:23.876845Z","shell.execute_reply":"2022-04-09T10:09:23.88095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(korquadQ), len(korquadK)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.883673Z","iopub.execute_input":"2022-04-09T10:09:23.883943Z","iopub.status.idle":"2022-04-09T10:09:23.893843Z","shell.execute_reply.started":"2022-04-09T10:09:23.883909Z","shell.execute_reply":"2022-04-09T10:09:23.89296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"korquadPair = pd.concat([ korquadQ, korquadK ]).sample(frac=1)\nkorquadPair.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.895446Z","iopub.execute_input":"2022-04-09T10:09:23.895727Z","iopub.status.idle":"2022-04-09T10:09:23.914554Z","shell.execute_reply.started":"2022-04-09T10:09:23.895691Z","shell.execute_reply":"2022-04-09T10:09:23.913739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_lengthes = korquadPair.input_text.str.len()\ntarget_lengthes = korquadPair.target_text.str.len()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.91612Z","iopub.execute_input":"2022-04-09T10:09:23.916401Z","iopub.status.idle":"2022-04-09T10:09:23.949656Z","shell.execute_reply.started":"2022-04-09T10:09:23.916365Z","shell.execute_reply":"2022-04-09T10:09:23.948852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_lengthes.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.951106Z","iopub.execute_input":"2022-04-09T10:09:23.951625Z","iopub.status.idle":"2022-04-09T10:09:23.964501Z","shell.execute_reply.started":"2022-04-09T10:09:23.951586Z","shell.execute_reply":"2022-04-09T10:09:23.963741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30, 5))\nsns.scatterplot(x=input_lengthes, y=target_lengthes)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:23.965984Z","iopub.execute_input":"2022-04-09T10:09:23.96649Z","iopub.status.idle":"2022-04-09T10:09:24.313989Z","shell.execute_reply.started":"2022-04-09T10:09:23.966451Z","shell.execute_reply":"2022-04-09T10:09:24.313253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30, 5))\nplt.xlim(300, 2300)\nsns.scatterplot(x=input_lengthes, y=target_lengthes)\nplt.axvline(2100)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:24.314988Z","iopub.execute_input":"2022-04-09T10:09:24.315243Z","iopub.status.idle":"2022-04-09T10:09:24.661575Z","shell.execute_reply.started":"2022-04-09T10:09:24.315208Z","shell.execute_reply":"2022-04-09T10:09:24.660104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"korquadPair = korquadPair[korquadPair['input_text'].str.len() < 2100]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:24.662968Z","iopub.execute_input":"2022-04-09T10:09:24.663452Z","iopub.status.idle":"2022-04-09T10:09:24.684874Z","shell.execute_reply.started":"2022-04-09T10:09:24.663412Z","shell.execute_reply":"2022-04-09T10:09:24.684003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = korquadPair.input_text.apply(tokenizer.tokenize)\ntarget_ids = korquadPair.target_text.apply(tokenizer.tokenize)\n\nkorquadPair['input_id'] = input_ids\nkorquadPair['target_id'] = target_ids","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:24.6864Z","iopub.execute_input":"2022-04-09T10:09:24.686704Z","iopub.status.idle":"2022-04-09T10:09:38.751126Z","shell.execute_reply.started":"2022-04-09T10:09:24.68666Z","shell.execute_reply":"2022-04-09T10:09:38.750331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30, 5))\nsns.scatterplot(x=input_ids.apply(len), y=target_ids.apply(len))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:38.752982Z","iopub.execute_input":"2022-04-09T10:09:38.753679Z","iopub.status.idle":"2022-04-09T10:09:39.305326Z","shell.execute_reply.started":"2022-04-09T10:09:38.753631Z","shell.execute_reply":"2022-04-09T10:09:39.304248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"korquadPair['input_id'].apply(len).describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:39.30688Z","iopub.execute_input":"2022-04-09T10:09:39.307257Z","iopub.status.idle":"2022-04-09T10:09:39.331533Z","shell.execute_reply.started":"2022-04-09T10:09:39.307214Z","shell.execute_reply":"2022-04-09T10:09:39.330369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(30, 5))\nsns.scatterplot(x=korquadPair['input_id'].apply(len), y=korquadPair['target_id'].apply(len))\nplt.axvline(512)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:39.333205Z","iopub.execute_input":"2022-04-09T10:09:39.334393Z","iopub.status.idle":"2022-04-09T10:09:39.77271Z","shell.execute_reply.started":"2022-04-09T10:09:39.334349Z","shell.execute_reply":"2022-04-09T10:09:39.772001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(korquadPair['input_id'].apply(len) < 512).value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:39.774039Z","iopub.execute_input":"2022-04-09T10:09:39.774411Z","iopub.status.idle":"2022-04-09T10:09:39.79887Z","shell.execute_reply.started":"2022-04-09T10:09:39.774377Z","shell.execute_reply":"2022-04-09T10:09:39.797869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"korquadPair = korquadPair[korquadPair['input_id'].apply(len) < 512]","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:39.804936Z","iopub.execute_input":"2022-04-09T10:09:39.805401Z","iopub.status.idle":"2022-04-09T10:09:39.828948Z","shell.execute_reply.started":"2022-04-09T10:09:39.80537Z","shell.execute_reply":"2022-04-09T10:09:39.828218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"korquadPair.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:39.831868Z","iopub.execute_input":"2022-04-09T10:09:39.832085Z","iopub.status.idle":"2022-04-09T10:09:39.850542Z","shell.execute_reply.started":"2022-04-09T10:09:39.832058Z","shell.execute_reply":"2022-04-09T10:09:39.849636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"korquadPair['input_text'].apply(lambda text: text.split(\":\")[0].strip()).value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:39.852247Z","iopub.execute_input":"2022-04-09T10:09:39.853229Z","iopub.status.idle":"2022-04-09T10:09:39.889808Z","shell.execute_reply.started":"2022-04-09T10:09:39.853189Z","shell.execute_reply":"2022-04-09T10:09:39.889102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"KoBARTModel = BartForConditionalGeneration.from_pretrained(\"gogamza/kobart-base-v2\")","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:09:39.891222Z","iopub.execute_input":"2022-04-09T10:09:39.891488Z","iopub.status.idle":"2022-04-09T10:10:00.08966Z","shell.execute_reply.started":"2022-04-09T10:09:39.891452Z","shell.execute_reply":"2022-04-09T10:10:00.088897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8\nMAX_LENGTH = 512","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:10:00.090828Z","iopub.execute_input":"2022-04-09T10:10:00.091499Z","iopub.status.idle":"2022-04-09T10:10:00.095814Z","shell.execute_reply.started":"2022-04-09T10:10:00.091459Z","shell.execute_reply":"2022-04-09T10:10:00.095128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = KoBARTConditionalGeneration({\n    \"lr\": 5e-5,\n    \"gpus\": 1,\n    \"num_nodes\": 1,\n    \"batch_size\": BATCH_SIZE,\n    \"max_epochs\": 2,\n    \"warmup_ratio\": 0.1,\n    \"max_seq_len\": MAX_LENGTH\n}, tokenizer=tokenizer, model=KoBARTModel)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:10:00.096992Z","iopub.execute_input":"2022-04-09T10:10:00.097571Z","iopub.status.idle":"2022-04-09T10:10:00.116076Z","shell.execute_reply.started":"2022-04-09T10:10:00.097534Z","shell.execute_reply":"2022-04-09T10:10:00.115219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dm = OneSourceDataModule(\n    korquadPair,\n    DatasetFromDataframe,\n    tokenizer,\n    MAX_LENGTH,\n    BATCH_SIZE\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:10:00.117771Z","iopub.execute_input":"2022-04-09T10:10:00.118048Z","iopub.status.idle":"2022-04-09T10:10:00.125674Z","shell.execute_reply.started":"2022-04-09T10:10:00.118013Z","shell.execute_reply":"2022-04-09T10:10:00.12484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor='val_loss',\n    dirpath=\".\",\n    filename='model_chp/{epoch:02d}-{val_loss:.3f}',\n    verbose=True,\n    save_last=True,\n    mode='min',\n    save_top_k=-1\n  )","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:10:00.128261Z","iopub.execute_input":"2022-04-09T10:10:00.128573Z","iopub.status.idle":"2022-04-09T10:10:00.139819Z","shell.execute_reply.started":"2022-04-09T10:10:00.128543Z","shell.execute_reply":"2022-04-09T10:10:00.138797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tb_logger = pl_loggers.TensorBoardLogger(os.path.join(\".\", 'tb_logs'))\nlr_logger = pl.callbacks.LearningRateMonitor()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:10:00.141131Z","iopub.execute_input":"2022-04-09T10:10:00.14182Z","iopub.status.idle":"2022-04-09T10:10:00.146846Z","shell.execute_reply.started":"2022-04-09T10:10:00.14178Z","shell.execute_reply":"2022-04-09T10:10:00.145925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(**({\n    \"gpus\": 1,\n    \"num_nodes\": 1,\n    \"max_epochs\": 2,\n}), logger=tb_logger, callbacks=[checkpoint_callback, lr_logger])","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:10:00.14819Z","iopub.execute_input":"2022-04-09T10:10:00.148885Z","iopub.status.idle":"2022-04-09T10:10:00.214862Z","shell.execute_reply.started":"2022-04-09T10:10:00.148849Z","shell.execute_reply":"2022-04-09T10:10:00.213844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, dm)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:10:00.21713Z","iopub.execute_input":"2022-04-09T10:10:00.217836Z","iopub.status.idle":"2022-04-09T10:51:09.082553Z","shell.execute_reply.started":"2022-04-09T10:10:00.217769Z","shell.execute_reply":"2022-04-09T10:51:09.081709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text = korquadPair.sample(frac=1).iloc[0].input_text\nprint(input_text)\nprint()\nprint(model.chat(input_text))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:51:09.08442Z","iopub.execute_input":"2022-04-09T10:51:09.084691Z","iopub.status.idle":"2022-04-09T10:51:12.406573Z","shell.execute_reply.started":"2022-04-09T10:51:09.084652Z","shell.execute_reply":"2022-04-09T10:51:12.405771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def createQuestions(article, num_questions):\n    keywords = model.chat(\"키워드 추출: \" + str(num_questions) + \"<unused1>\" + article).split(\"<unused2>\")\n    keywords = list(set([keyword.strip() for keyword in keywords]))\n    print(keywords)\n    \n    questions = [model.chat(\"질문 생성: \" + keyword + \"<unused0>\" + article) for keyword in keywords]\n    \n    return questions\n\ncreateQuestions(\" \".join(\"\"\"\n임진왜란은 1592년부터 1598년까지 2차에 걸쳐서 우리나라에 침입한 일본과의 싸움이다.\n엄청난 시련을 겪으면서도 끈질긴 저항으로 이겨내고 각성과 자기성찰을 바탕으로 민족의 운명을\n새로 개척해나간 계기가 된 전쟁이다. 명의 원조도 있었지만 승리의 가장 큰 원동력은 max으로,\n이순신에 의한 제해권의 장악과 전국에서 봉기한 의병의 활동은 불리했던 전쟁 국면을 전환시킨 결정적인\n힘이었다. 이 전란은 동아시아의 국제 정세를 크게 변화시키는 결과를 가져와, 명과 청이 교체되면서\n병자호란이라는 시련을 예고하기도 했다.\n\n조선이 임진왜란을 당하여 전쟁 초기 이를 감당하기 어려울 정도로 국력이 쇠약해진 것은\n왜란이 일어난 선조대에 이르러서 비롯된 것은 아니었다. 이미 훨씬 이전부터 중쇠의 기운이\n나타나기 시작하였다.정치적으로는 연산군 이후 명종대에 이르는 4대 사화와 훈구·사림 세력간에\n계속된 정쟁으로 인한 중앙 정계의 혼란, 사림 세력이 득세한 선조 즉위 이후 격화된 당쟁\n등으로 정치의 정상적인 운영을 수행하기 어려운 지경이었다.군사적으로도 조선 초기에 설치된\n국방체제가 붕괴되어 외침에 대비하기 위한 방책으로 군국기무를 장악하는 비변사라는 합의 기관을\n설치했으나, 이것 또한 정상적인 기능을 발휘하지 못하였다.이이는 남왜북호의\n침입에 대처하기 위하여 십만양병설을 주장하기도 하였다. 그러나 국가 재정의 허약으로\n뜻을 이루지 못하고, 사회는 점점 해이해지고 문약에 빠져 근본적인 국가 방책이 확립되지\n못한 실정이었다.이러할 즈음 일본에서는 새로운 형세가 전개되고 있었다. 즉, 15세기 후반\n서세동점에 따라 일본에는 유럽 상인들이 들어와 신흥 상업 도시가 발전되어 종래의 봉건적인 지배\n형태가 위협받기 시작하였다.\n\"\"\".strip().split(\"\\n\")), 9)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T10:51:12.408115Z","iopub.execute_input":"2022-04-09T10:51:12.408705Z","iopub.status.idle":"2022-04-09T10:51:35.520603Z","shell.execute_reply.started":"2022-04-09T10:51:12.408666Z","shell.execute_reply":"2022-04-09T10:51:35.51988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Author: Rycont Park | rycont@outlook.kr   \n한국디지털미디어고등학교 \"공업일반\" 프로젝트 과제","metadata":{}}]}